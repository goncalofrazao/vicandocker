{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "import scipy.io as sio\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "\n",
    "from vican.cam import estimate_pose_mp, SE3\n",
    "from vican.bipgo import bipartite_se3sync\n",
    "from vican.dataset import Dataset\n",
    "\n",
    "# remove all timestep with less than 2 cameras\n",
    "def filter_dataset(dataset_path='dataset/Dataset_Sensei/contlabs/aruco_images_samples'):\n",
    "    for timestep in os.listdir(dataset_path):\n",
    "        if not os.path.isdir(os.path.join(dataset_path, timestep)):\n",
    "            print(f'{timestep} is not a directory')\n",
    "            continue\n",
    "\n",
    "        os.system(f'rm {os.path.join(dataset_path, timestep, \".gitkeep\")} 2>/dev/null')\n",
    "\n",
    "        cameras = [i for i in os.listdir(os.path.join(dataset_path, timestep)) if i.endswith('.jpg')]\n",
    "        if len(cameras) < 2:\n",
    "            print(f'Not enough cameras for timestep {timestep}')\n",
    "            os.system(f'rm -rf {os.path.join(dataset_path, timestep)}')\n",
    "\n",
    "# get resolution of all images in a dataset\n",
    "def get_all_resolutions(folder='dataset/Dataset_Sensei/contlabs/aruco_images_samples'):\n",
    "    resolutions = set()\n",
    "\n",
    "    for directory in os.listdir(folder):\n",
    "        if not os.path.isdir(f'{folder}/{directory}'):\n",
    "            continue\n",
    "        os.system(f'rm {folder}/{directory}/.gitkeep 2> /dev/null')\n",
    "\n",
    "        if len(os.listdir(f'{folder}/{directory}')) < 2:\n",
    "            os.system(f'rm -rf {folder}/{directory}')\n",
    "            continue\n",
    "        # print(f'{folder}/{directory}')\n",
    "        for file in os.listdir(f'{folder}/{directory}'):\n",
    "            if file.endswith('jpg'):\n",
    "                resolutions.add(Image.open(f'{folder}/{directory}/{file}').size)\n",
    "\n",
    "    return resolutions\n",
    "\n",
    "# convert file of intrinsics to cameras.json\n",
    "def generate_cameras_json(intrinsics_path='dataset/Dataset_Sensei/contlabs/cameras_intrinsics.json', cameras_path='dataset/Dataset_Sensei/contlabs/aruco_images_samples/cameras.json'):\n",
    "    data = json.load(open(intrinsics_path))\n",
    "    new_data = {}\n",
    "    for i in data:\n",
    "        intrinsics = data[i]['intrinsics']\n",
    "        distortion = data[i]['distortion']\n",
    "        new_data[i] = {\n",
    "            'fx': intrinsics[0][0],\n",
    "            'fy': intrinsics[1][1],\n",
    "            'cx': intrinsics[0][2],\n",
    "            'cy': intrinsics[1][2],\n",
    "            'resolution_x': 1280,\n",
    "            'resolution_y': 720,\n",
    "            'distortion': distortion\n",
    "        }\n",
    "\n",
    "    print(new_data.keys())\n",
    "    json.dump(new_data, open(cameras_path, 'w'), indent=4)\n",
    "\n",
    "# read object file and create obj_pose_est\n",
    "def get_obj_pose_est(file_path='dataset/Dataset_Sensei/contlabs/aruco_cube_transformations.json'):\n",
    "    data = json.load(open(file_path))\n",
    "    obj_pose_est = {}\n",
    "\n",
    "    for i in data['to']:\n",
    "        if not i == 'floor':\n",
    "            obj_pose_est[i] = SE3(pose=np.array(data['to'][i]))\n",
    "\n",
    "    return obj_pose_est\n",
    "\n",
    "# calibrate cameras with object pose estimation and cameras dataset\n",
    "def get_cam_pose_est(obj_pose_est, dataset_path='dataset/Dataset_Sensei/contlabs/aruco_images_samples', err=0.5):\n",
    "    dataset = Dataset(root=dataset_path)\n",
    "\n",
    "    MARKER_IDS = list(obj_pose_est.keys())\n",
    "\n",
    "    cam_marker_edges = estimate_pose_mp(cams=dataset.im_data['cam'],\n",
    "                                        im_filenames=dataset.im_data['filename'],\n",
    "                                        aruco='DICT_4X4_1000',\n",
    "                                        marker_size=0.575,\n",
    "                                        corner_refine='CORNER_REFINE_SUBPIX',\n",
    "                                        marker_ids=MARKER_IDS,\n",
    "                                        flags='SOLVEPNP_IPPE_SQUARE',\n",
    "                                        brightness=-50,\n",
    "                                        contrast=100)\n",
    "\n",
    "    pose_est = bipartite_se3sync(cam_marker_edges,\n",
    "                                constraints=obj_pose_est,\n",
    "                                noise_model_r=lambda edge : 1, #0.001 * Polygon(zip(edge['corners'][:,0], edge['corners'][:,1])).area**1.0,\n",
    "                                noise_model_t=lambda edge : 1, #0.001 * Polygon(zip(edge['corners'][:,0], edge['corners'][:,1])).area**1.0,\n",
    "                                edge_filter=lambda edge : edge['reprojected_err'] < err,\n",
    "                                maxiter=4,\n",
    "                                lsqr_solver=\"conjugate_gradient\",\n",
    "                                dtype=np.float32)\n",
    "    return pose_est\n",
    "\n",
    "# generate output file for pose of cameras\n",
    "def cam_pose_est_json_dump(pose_est, file_path='pose_est.json'):\n",
    "    json_data = {}\n",
    "    for i in pose_est:\n",
    "        json_data[i] = {'R': pose_est[i].R().tolist(), 't': pose_est[i].t().tolist()}\n",
    "\n",
    "    json.dump(json_data, open(file_path, 'w'), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reprojection error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_cameras_json(intrinsics_path='small_dataset/cameras_intrinsics.json', cameras_path='small_dataset/aruco_images_samples/cameras.json')\n",
    "dataset = Dataset(root='small_dataset/aruco_images_samples')\n",
    "\n",
    "MARKER_IDS = ['0', '1', '2', '3', '4']\n",
    "\n",
    "cam_marker_edges = estimate_pose_mp(cams=dataset.im_data['cam'],\n",
    "                                    im_filenames=dataset.im_data['filename'],\n",
    "                                    aruco='DICT_4X4_1000',\n",
    "                                    marker_size=0.575,\n",
    "                                    corner_refine='CORNER_REFINE_SUBPIX',\n",
    "                                    marker_ids=MARKER_IDS,\n",
    "                                    flags='SOLVEPNP_IPPE_SQUARE',\n",
    "                                    brightness=-50,\n",
    "                                    contrast=100)\n",
    "len(cam_marker_edges.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot an histogram of the reprojected errors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "errors = np.array([edge['reprojected_err'] for edge in cam_marker_edges.values()])\n",
    "plt.hist(errors, bins=100)\n",
    "plt.show()\n",
    "\n",
    "error = 0.5\n",
    "errors_2 = np.sum(errors < error)\n",
    "print(f'Errors < {error}: {errors_2} of {len(errors)} ({errors_2/len(errors)*100:.2f}%)')\n",
    "print(f'Mean error: {np.mean(errors)}\\nMax error: {np.max(errors)}\\nMin error: {np.min(errors)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_errors = np.array([int(edge['im_filename'].split('/')[-1].split('.')[0]) for edge in cam_marker_edges.values()])\n",
    "\n",
    "cameras_filter = []\n",
    "for i in np.unique(im_errors):\n",
    "    errors_i = errors[im_errors == i]\n",
    "    percentage = np.sum(errors_i < error) / len(errors_i) * 100\n",
    "    if percentage > 99:\n",
    "        cameras_filter.append(i)\n",
    "        print(f'{i}: Errors < {error}: ({percentage:.2f}%)')\n",
    "    \n",
    "    # plt.hist(errors_i, bins=100)\n",
    "    # plt.title(f'{i}')\n",
    "    # plt.show()\n",
    "    # print(f'Mean error: {np.mean(errors_i)}\\nMax error: {np.max(errors_i)}\\nMin error: {np.min(errors_i)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_small_dataset(cameras_number=1000)\n",
    "generate_cameras_json(intrinsics_path='small_dataset/cameras_intrinsics.json', cameras_path='small_dataset/aruco_images_samples/cameras.json')\n",
    "\n",
    "obj_pose_est = get_obj_pose_est(file_path='small_dataset/aruco_cube_transformations.json')\n",
    "pose_est = get_cam_pose_est(obj_pose_est, dataset_path='small_dataset/aruco_images_samples', err=0.5)\n",
    "cam_pose_est_json_dump(pose_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate cameras_intrinsics.json file with camera '159' repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = {}\n",
    "json_data = json.load(open('dataset/Dataset_Sensei/contlabs/cameras_intrinsics.json'))\n",
    "for i in json_data:\n",
    "    new_data[i] = json_data['159']\n",
    "\n",
    "json.dump(new_data, open('cameras_intrinsics.json', 'w'), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all distortion coefficients\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "json_data = json.load(open('dataset/Dataset_Sensei/contlabs/cameras_intrinsics.json'))\n",
    "max_idx = max([int(i) for i in json_data])\n",
    "distortion_coefficients = np.zeros((max_idx + 1, 8))\n",
    "intrinsics = np.zeros((max_idx + 1, 3, 3))\n",
    "\n",
    "for i, coeffs in enumerate(json_data):\n",
    "    intrinsics[int(coeffs)] += np.array(np.array(json_data[coeffs]['intrinsics']))\n",
    "    distortion_coefficients[int(coeffs)] += np.array(json_data[coeffs]['distortion'][0])[:8]\n",
    "\n",
    "intrinsics.shape, distortion_coefficients.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster the dirtortion coefficients\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import umap\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "labels = kmeans.fit_predict(distortion_coefficients)\n",
    "\n",
    "reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "embeddings = reducer.fit_transform(distortion_coefficients)\n",
    "\n",
    "plt.scatter(embeddings[:,0], embeddings[:,1], c=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "dataset = 'Dataset_Sensei/contlabs'\n",
    "cluster = 1\n",
    "\n",
    "dataset_path = f'dataset/{dataset}/aruco_images_samples'\n",
    "all_cameras = set([int((i.split('.')[0]).split('/')[-1]) for i in glob.glob(f'{dataset_path}/*/*.jpg')])\n",
    "\n",
    "intrinsics_data = json.load(open(f'dataset/{dataset}/cameras_intrinsics.json'))\n",
    "\n",
    "for i in all_cameras:\n",
    "    if labels[i] != cluster:\n",
    "        continue\n",
    "    ims = [cv2.imread(im) for im in glob.glob(f'{dataset_path}/*/{i}.jpg')]\n",
    "    undistorted_im = [cv2.undistort(im, intrinsics[i], distortion_coefficients[i]) for im in ims]\n",
    "\n",
    "    fig, axs = plt.subplots(1, 5, figsize=(15,5))\n",
    "    for ax in axs:\n",
    "        ax.axis('off')\n",
    "    for im, ax in zip(undistorted_im, axs):\n",
    "        ax.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f'Undistorted images from camera {i}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset with selected cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "def clean_dataset(dataset_path):\n",
    "    for i in glob.glob(f'{dataset_path}/aruco_images_samples/*'):\n",
    "        if len(glob.glob(f'{i}/*.jpg')) < 2:\n",
    "            os.system(f'rm -rf {i}')\n",
    "\n",
    "def build_small_dataset(cameras_list, old_dataset_path='dataset/Dataset_Sensei/contlabs', new_dataset_path='small_dataset'):\n",
    "    os.makedirs(new_dataset_path, exist_ok=True)\n",
    "    os.system(f'cp -r {old_dataset_path}/* {new_dataset_path}')\n",
    "\n",
    "    for i in glob.glob(f'{new_dataset_path}/aruco_images_samples/*/*.jpg'):\n",
    "        if int(i.split('/')[-1].split('.')[0]) not in cameras_list:\n",
    "            os.system(f'rm {i}')\n",
    "    \n",
    "cameras_list = set(np.where(labels == 1)[0])\n",
    "build_small_dataset(cameras_list)\n",
    "clean_dataset('small_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "dataset_path = 'small_dataset/aruco_images_samples'\n",
    "idx2camera = sorted(list(set([int(i.split('/')[-1].split('.')[0]) for i in glob.glob(f'{dataset_path}/*/*.jpg')])))\n",
    "camera2idx = {camera_id: i for i,camera_id in enumerate(idx2camera)}\n",
    "\n",
    "appearances = np.array([len(glob.glob(f'{dataset_path}/*/{camera_id}.jpg')) for camera_id in idx2camera])\n",
    "idx2camera = np.array(idx2camera)\n",
    "\n",
    "# cameras_filter = [int(i.split('.')[0].split('/')[-1]) for i in glob.glob(f'{dataset_path}/111/*.jpg')]\n",
    "cameras_filter = [141, 155, 168]\n",
    "for i in idx2camera:\n",
    "    if i not in cameras_filter:\n",
    "        for im in glob.glob(f'{dataset_path}/*/{i}.jpg'):\n",
    "            os.system(f'rm {im}')\n",
    "\n",
    "clean_dataset('small_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'small_dataset/aruco_images_samples'\n",
    "timesteps = np.array(sorted([int(i) for i in os.listdir(dataset_path)]))\n",
    "timesteps_density = np.array([len(glob.glob(f'{dataset_path}/{timestep}/*.jpg')) for timestep in timesteps])\n",
    "# timesteps[timesteps_density == 4]\n",
    "timesteps_density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if graph is connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csgraph\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "dataset_path = 'small_dataset/aruco_images_samples'\n",
    "idx2camera = set(sorted([int(i.split('/')[-1].split('.')[0]) for i in glob.glob(f'{dataset_path}/*/*.jpg')]))\n",
    "camera2idx = {camera_id: i for i,camera_id in enumerate(idx2camera)}\n",
    "\n",
    "adjacency_matrix = np.zeros((len(idx2camera), len(idx2camera)), dtype=int)\n",
    "\n",
    "for timestep in os.listdir(dataset_path):\n",
    "    timestep_path = f'{dataset_path}/{timestep}'\n",
    "    if not os.path.isdir(timestep_path):\n",
    "        continue\n",
    "\n",
    "    cameras = [int(i.split('/')[-1].split('.')[0]) for i in glob.glob(f'{timestep_path}/*.jpg')]\n",
    "\n",
    "    for i in range(len(cameras)):\n",
    "        for j in range(i+1, len(cameras)):\n",
    "            adjacency_matrix[camera2idx[cameras[i]], camera2idx[cameras[j]]] += 1\n",
    "            adjacency_matrix[camera2idx[cameras[j]], camera2idx[cameras[i]]] += 1\n",
    "\n",
    "\n",
    "x = csgraph.connected_components(adjacency_matrix, directed=False)\n",
    "x, idx2camera\n",
    "[idx for i, idx in enumerate(idx2camera) if x[1][i] == 2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test PNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "arucos_distance = []\n",
    "\n",
    "# dataset_path = 'dataset/Dataset_Sensei/contlabs/aruco_images_samples/*/*.jpg'\n",
    "dataset_path = 'small_dataset/aruco_images_samples/*/*.jpg'\n",
    "for f in glob.glob(dataset_path):\n",
    "    im = cv2.imread(f)\n",
    "    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    camera_id = f.split('/')[-1].split('.')[0]\n",
    "    camera_data = json.load(open('small_dataset/cameras_intrinsics.json'))[str(camera_id)]\n",
    "    intrinsics, distortion = np.array(camera_data['intrinsics']), np.array(camera_data['distortion'])\n",
    "\n",
    "    dictionary = cv2.aruco.Dictionary_get(cv2.aruco.DICT_4X4_1000)\n",
    "    parameters = cv2.aruco.DetectorParameters_create()\n",
    "    marker_corners, marker_ids, _ = cv2.aruco.detectMarkers(gray, dictionary, parameters=parameters)\n",
    "\n",
    "    if marker_ids is None:\n",
    "        continue\n",
    "\n",
    "    marker_corners = np.array(marker_corners).reshape(-1, 4, 2)\n",
    "    marker_ids = np.array(marker_ids).flatten()\n",
    "\n",
    "    marker_corners = marker_corners[marker_ids < 5]\n",
    "    marker_ids = marker_ids[marker_ids < 5]\n",
    "\n",
    "    marker_points = np.array([[-1, 1, 0],\n",
    "                                [1, 1, 0],\n",
    "                                [1, -1, 0],\n",
    "                                [-1, -1, 0]], dtype=np.float32)\n",
    "    marker_points *= 0.575 * 0.5\n",
    "    points3d = np.zeros((len(marker_corners), 3))\n",
    "\n",
    "    for i in range(len(marker_corners)):\n",
    "        flag, r, t = cv2.solvePnP(marker_points,\n",
    "                           imagePoints=marker_corners[i].squeeze(),\n",
    "                           cameraMatrix=intrinsics,\n",
    "                           distCoeffs=distortion)\n",
    "\n",
    "        if not flag:\n",
    "            continue\n",
    "\n",
    "        r, t = cv2.solvePnPRefineLM(marker_points,\n",
    "                                    imagePoints=marker_corners[i].squeeze(),\n",
    "                                    cameraMatrix=intrinsics,\n",
    "                                    distCoeffs=distortion,\n",
    "                                    rvec=r,\n",
    "                                    tvec=t)\n",
    "        \n",
    "        points3d[i] += t.reshape(-1)\n",
    "\n",
    "    for corner in marker_corners:\n",
    "        cv2.drawContours(im, [corner.astype(int)], -1, (0, 255, 0), 2)\n",
    "    \n",
    "    if len(points3d) < 2:\n",
    "        continue\n",
    "\n",
    "    for i in range(len(points3d)):\n",
    "        for j in range(i+1, len(points3d)):\n",
    "            arucos_distance.append(np.linalg.norm(points3d[i] - points3d[j]))\n",
    "            # if arucos_distance[-1] > 1:\n",
    "            #     plt.imshow(im)\n",
    "\n",
    "            #     plt.title(f)\n",
    "            #     plt.show()\n",
    "\n",
    "arucos_distance = np.array(arucos_distance)\n",
    "arucos_distance = arucos_distance[arucos_distance < 10]\n",
    "\n",
    "plt.hist(arucos_distance, bins=100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete all images of a camera from a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "cameras_to_remove = glob.glob('small_dataset/aruco_images_samples/*/111.jpg')\n",
    "for camera in cameras_to_remove:\n",
    "    os.remove(camera)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slim-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
